{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tRSiDskIxyDA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# torch is just for the feature extractor and the dataset (NOT FOR IMPLEMENTING NEURAL NETWORKS!)\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet34\n",
        "import torch.nn as nn\n",
        "# sklearn is just for evaluation (NOT FOR IMPLEMENTING NEURAL NETWORKS!)\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qMq81U3yFpD",
        "outputId": "6698a32e-97b5-40e3-baa2-864f9f788ab4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 109MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "feature_extractor = resnet34(pretrained=True)\n",
        "input_dim = feature_extractor.fc.in_features\n",
        "for param in feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "feature_extractor.fc = nn.Identity()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTwdpv59yGBC",
        "outputId": "d59065cd-484c-4e56-c960-5f4eae31bd8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 69512430.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.CIFAR10('data', train=True,\n",
        "                              download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10('data', train=False,\n",
        "                             download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hckp6Q-LyIhY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4oLQvp-OyLeT"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KuAdFf4hDKly"
      },
      "outputs": [],
      "source": [
        "# importing numpy library\n",
        "import numpy as np\n",
        "\n",
        "# defining a class named RBFNet\n",
        "class RBFNet:\n",
        "    \n",
        "    # constructor method to initialize the attributes of the object, namely num_inputs, num_hidden, num_outputs and gamma.\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs, gamma=1.0):\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_outputs = num_outputs\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # initializing weights for hidden layer with random values\n",
        "        self.hidden_weights = np.random.rand(self.num_hidden, self.num_inputs)\n",
        "\n",
        "        # initializing biases for hidden layer with random values\n",
        "        self.hidden_biases = np.random.rand(self.num_hidden)\n",
        "\n",
        "        # initializing weights for output layer with random values\n",
        "        self.output_weights = np.random.rand(self.num_outputs, self.num_hidden)\n",
        "\n",
        "        # initializing biases for output layer with random values\n",
        "        self.output_biases = np.random.rand(self.num_outputs)\n",
        "\n",
        "    # method to calculate activation function for Radial Basis Function (RBF)\n",
        "    def rbf(self, x, c, s):\n",
        "        return np.exp(-self.gamma * np.linalg.norm(x-c)**2 / s**2)\n",
        "\n",
        "    # method to calculate the activation of hidden layer\n",
        "    def hidden_layer_activation(self, X):\n",
        "        Z = np.zeros((self.num_hidden, X.shape[0]))\n",
        "        for i in range(self.num_hidden):\n",
        "            for j in range(X.shape[0]):\n",
        "                Z[i, j] = self.rbf(X[j], self.hidden_weights[i], 1)\n",
        "        return Z.T\n",
        "\n",
        "    # method to perform forward propagation\n",
        "    def forward(self, X):\n",
        "        # calculate activation of hidden layer\n",
        "        hidden_layer_activation = self.hidden_layer_activation(X)\n",
        "\n",
        "        # calculate output of hidden layer\n",
        "        hidden_output = np.dot(hidden_layer_activation,\n",
        "                               self.output_weights.T) + self.output_biases\n",
        "\n",
        "        # apply softmax function to output\n",
        "        output = self.softmax(hidden_output)\n",
        "        return output\n",
        "\n",
        "    # method to calculate softmax function\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x))\n",
        "        return exp_x / exp_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # method to convert the output labels into one-hot encoded vectors\n",
        "    def one_hot(self, y):\n",
        "        onehot = np.zeros((y.size, self.num_outputs))\n",
        "        onehot[np.arange(y.size), y] = 1\n",
        "        return onehot\n",
        "\n",
        "    # method to make prediction using the trained model\n",
        "    def predict(self, X):\n",
        "        # calculate activation of hidden layer\n",
        "        hidden_layer_activation = self.hidden_layer_activation(X)\n",
        "\n",
        "        # calculate output of hidden layer\n",
        "        hidden_output = np.dot(hidden_layer_activation,\n",
        "                               self.output_weights.T) + self.output_biases\n",
        "\n",
        "        # apply softmax function to output\n",
        "        output = self.softmax(hidden_output)\n",
        "        \n",
        "        # return the index of the maximum value in each row of the 'output' array as a predicted class label.\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "    # method to train the RBF network\n",
        "    def train(self, X, y, lr=0.01, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            # calculate activation of hidden layer\n",
        "            hidden_layer_activation = self.hidden_layer_activation(X)\n",
        "\n",
        "            # calculate output of hidden layer\n",
        "            hidden_output = np.dot(\n",
        "                hidden_layer_activation, self.output_weights.T) + self.output_biases\n",
        "\n",
        "            # apply softmax function to output\n",
        "            output = self.softmax(hidden_output)\n",
        "\n",
        "            # calculate error between predicted and actual output\n",
        "            error = self.one_hot(y) - output\n",
        "            \n",
        "            # calculate gradient of output weights and biases\n",
        "            output_weights_gradient = - \\\n",
        "                np.dot(error.T, hidden_layer_activation) / X.shape[0]\n",
        "            output_biases_gradient = -np.mean(error, axis=0)\n",
        "\n",
        "            # backpropagate error to hidden layer\n",
        "            hidden_error = np.dot(error, self.output_weights) * \\\n",
        "                (hidden_layer_activation * (1 - hidden_layer_activation))\n",
        "\n",
        "            # calculate gradient of hidden weights and biases\n",
        "            hidden_weights_gradient = -np.dot(hidden_error.T, X) / X.shape[0]\n",
        "            hidden_biases_gradient = -np.mean(hidden_error, axis=0)\n",
        "\n",
        "            # update weights and biases\n",
        "            self.output_weights -= lr * output_weights_gradient\n",
        "            self.output_biases -= lr * output_biases_gradient\n",
        "            self.hidden_weights -= lr * hidden_weights_gradient\n",
        "            self.hidden_biases -= lr * hidden_biases_gradient\n",
        "\n",
        "            # print loss for each epoch\n",
        "            loss = np.mean(np.square(error))\n",
        "            if epoch % 10 == 0:\n",
        "                print(\"Epoch %d: loss = %.6f\" % (epoch, loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOciu92XM2k",
        "outputId": "7b505d9a-5cf5-4d5a-a44e-e2af2d89b5e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.999375"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(random_state=1, max_iter=1000,\n",
        "                    hidden_layer_sizes=[20]).fit(result, Y)\n",
        "clf.score(result, Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ew2L8GsP6Ih",
        "outputId": "eb717694-dcf3-4b19-92ef-63b832045b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss = 0.090674\n",
            "Epoch 10: loss = 0.090660\n",
            "Epoch 20: loss = 0.090646\n",
            "Epoch 30: loss = 0.090632\n",
            "Epoch 40: loss = 0.090619\n",
            "Epoch 50: loss = 0.090606\n",
            "Epoch 60: loss = 0.090593\n",
            "Epoch 70: loss = 0.090581\n",
            "Epoch 80: loss = 0.090569\n",
            "Epoch 90: loss = 0.090557\n"
          ]
        }
      ],
      "source": [
        "rbf = RBFNet(512, 20, 10)\n",
        "rbf.train(result, Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK05gH1mTxgd",
        "outputId": "8b88d132-57ed-4c42-9121-225df82e858c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rbf.predict(result[0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbI2vDNxQnsd",
        "outputId": "050e7940-43c1-4590-a48b-df6fe1c3acc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RBF accuracy:\n",
            "0.096875\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "for i, t in enumerate(result):\n",
        "    if rbf.predict(t)[0] == Y[i]:\n",
        "        counter += 1\n",
        "print(\"RBF accuracy:\")\n",
        "print(counter / len(result))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
