{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet34 in tensorflow\n",
    "https://www.youtube.com/watch?v=_W7NFiSrDOU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 hidden layer and 1 layer output\n",
    "def mlp_0Hidden(activation_output, X, y):\n",
    "    \"\"\" MLP with 0 hidden layer and 1 output layer\n",
    "    Args:\n",
    "      activation_output (function) : activation function for output layer\n",
    "      X (ndarray (N, M))           : input data, N samples, M features\n",
    "      y (ndarray (N,))             : input labels, N samples\n",
    "    Returns:\n",
    "      model (Sequential)           : keras model\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(output_size, activation=activation_output, input_shape=(input_size,)) # output layer\n",
    "    ])\n",
    "    ### END CODE HERE ### \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 hidden layer and  1 layer output \n",
    "def mlp_1Hidden(num_neuron, activation_hidden, activation_output = 'sigmoid', X, y):\n",
    "    \"\"\" MLP with 1 hidden layer and 1 output layer\n",
    "    Args:\n",
    "      num_neuron (int)             : number of neurons in the hidden layer\n",
    "      activation_hidden (function) : activation function for hidden layer\n",
    "      activation_output (function) : activation function for output layer\n",
    "      X (ndarray (N, M))           : input data, N samples, M features\n",
    "      y (ndarray (N,))             : input labels, N samples\n",
    "    Returns:\n",
    "      model (Sequential)           : keras model\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(num_neuron, activation=activation_hidden, input_shape=(input_size,)),\n",
    "    tf.keras.layers.Dense(output_size, activation=activation_output)')\n",
    "    ])\n",
    "    ### END CODE HERE ### \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 hidden layers and 1 layer output\n",
    "def mlp_2Hidden(num_neuron_L1, num_neuron_L2, activation_hidden, activation_output, X, y):\n",
    "    \"\"\" MLP with 2 hidden layers and 1 output layer\n",
    "    Args:\n",
    "      num_neuron_L1 (int)          : number of neurons in the 1st hidden layer\n",
    "      num_neuron_L2 (int)          : number of neurons in the 2nd hidden layer\n",
    "      activation_hidden (function) : activation function for hidden layer\n",
    "      activation_output (function) : activation function for output layer\n",
    "      X (ndarray (N, M))           : input data, N samples, M features\n",
    "      y (ndarray (N,))             : input labels, N samples\n",
    "    Returns:\n",
    "      model (Sequential)           : keras model\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(num_neuron_L1, activation=activation_hidden, input_shape=(input_size,)),\n",
    "    tf.keras.layers.Dense(num_neuron_L2, activation=activation_hidden),\n",
    "    tf.keras.layers.Dense(output_size, activation=activation_output)\n",
    "    ])\n",
    "    ### END CODE HERE ### \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_0Hidden(sigmoid, X, y)\n",
    "# model = mlp_1Hidden(4, sigmoid, sigmoid, X, y)\n",
    "# model = mlp_2Hidden(4, 4, sigmoid, sigmoid, X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on your data\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights for each layer\n",
    "hidden1_weights, hidden1_biases = model.layers[0].get_weights()\n",
    "hidden2_weights, hidden2_biases = model.layers[1].get_weights()\n",
    "output_weights, output_biases = model.layers[2].get_weights()\n",
    "\n",
    "# Print the shapes of the weights for each layer\n",
    "print('Hidden layer 1 weights shape:', hidden1_weights.shape)\n",
    "print('Hidden layer 2 weights shape:', hidden2_weights.shape)\n",
    "print('Output layer weights shape:', output_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image_of_two.reshape(1,400))  # prediction\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_feature_extraction(type):\n",
    "    if type == 1:\n",
    "        return 'ResNet34'\n",
    "    elif type == 2:\n",
    "        return 'ResNet18'\n",
    "    else\n",
    "        return 'VGG11'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_activation(type):\n",
    "    if type == 1:\n",
    "        return 'sigmoid'\n",
    "    else:\n",
    "        return 'relu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# chromosome \n",
    "temp2 = [{'feature extraction': 1, 'hidden layer': [20, 30, 30], 'activation function': 2}, {'feature extraction': 2, 'hidden layer': [30, 10], 'activation function': 1}, {'feature extraction': 1, 'hidden layer': [], 'activation function': 2}, {'feature extraction': 1, 'hidden layer': [10], 'activation function': 1}, {'feature extraction': 3, 'hidden layer': [10, 30, 10], 'activation function': 1}, {'feature extraction': 2, 'hidden layer': [20, 30, 20], 'activation function': 1}, {'feature extraction': 3, 'hidden layer': [30, 20, 20], 'activation function': 1}, {'feature extraction': 2, 'hidden layer': [10, 10], 'activation function': 1}, {'feature extraction': 2, 'hidden layer': [20], 'activation function': 1}, {'feature extraction': 1, 'hidden layer': [], 'activation function': 1}]\n",
    "print(temp2[1]['feature extraction'])\n",
    "type_of_feature_extraction = decode_feature_extraction(temp2[0]['feature extraction'])\n",
    "type_of_activation_function = decode_activation(temp2[0]['activation function'])\n",
    "number_of_hidden_layers = len(temp2[0]['hidden layer'])\n",
    "if number_of_hidden_layers == 0:\n",
    "    model = mlp_0Hidden(type_of_activation_function, X, y)\n",
    "elif number_of_hidden_layers == 1:\n",
    "    model = mlp_1Hidden(temp2[0]['hidden layer'][0], type_of_activation_function, 'sigmoid', X, y)\n",
    "else:\n",
    "    model = mlp_2Hidden(temp2[0]['hidden layer'][0], temp2[0]['hidden layer'][1], type_of_activation_function, 'sigmoid', X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualte the accuracy MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have already trained your MLP model and obtained predictions on a validation set\n",
    "y_true = [...] # True labels of the validation set (numpy array or list)\n",
    "y_pred = [...] # Predicted labels of the validation set (numpy array or list)\n",
    "\n",
    "# Convert the label arrays to tensors if necessary\n",
    "y_true = tf.convert_to_tensor(y_true)\n",
    "y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.math.equal(y_true, tf.round(y_pred)), dtype=tf.float32))\n",
    "# tf.math.equal compares the true labels with the predicted labels rounded to the nearest integer\n",
    "# tf.cast converts the boolean values to floating point numbers (0 or 1)\n",
    "# tf.reduce_mean takes the mean of the resulting tensor to obtain the accuracy\n",
    "\n",
    "# Alternatively, you can use the tf.keras.metrics.Accuracy class to calculate the accuracy\n",
    "accuracy_metric = tf.keras.metrics.Accuracy()\n",
    "accuracy_metric.update_state(y_true, tf.round(y_pred))\n",
    "accuracy = accuracy_metric.result().numpy()\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
